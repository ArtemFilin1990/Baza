# Автоматический конвейер обработки файлов подшипников

Этот документ описывает автоматическую систему обработки файлов с данными по подшипникам.

## Требования

- Python 3.11+
- Зависимости из `requirements.txt`

## Установка

```bash
pip install -r requirements.txt
```

## Быстрый старт

Запустите конвейер в режиме наблюдения:

```bash
python -m app watch
```

Или используйте скрипт:

```bash
./bin/run watch
```

## Режимы работы

### `watch` - Режим наблюдения

Наблюдает за директорией `inbox/` и автоматически обрабатывает новые файлы.

```bash
python -m app watch
```

По умолчанию использует polling (опрос директории каждые 5 секунд).

### `once` - Единоразовая обработка

Обрабатывает все файлы в `inbox/` один раз и завершается.

```bash
python -m app once
```

### `rebuild` - Пересборка каталога

Пересобирает единый каталог из всех файлов в `processed/`.

```bash
python -m app rebuild
```

## Структура директорий

- `inbox/` - входящие файлы для обработки
- `processed/` - успешно обработанные файлы
- `error/` - файлы с ошибками
- `out/` - выходные артефакты
- `logs/` - логи системы
- `config/` - конфигурационные файлы

## Конфигурация

### Основной файл: `config/app.yaml`

```yaml
paths:
  inbox: "inbox"
  processed: "processed"
  error: "error"
  out: "out"
  logs: "logs"

watcher:
  mode: "polling"              # polling или watchdog
  interval_seconds: 5          # интервал опроса
  min_file_age_seconds: 2      # минимальный возраст файла

limits:
  max_file_size_mb: 50         # максимальный размер файла

normalization:
  brand_case: "upper"          # приведение брендов к верхнему регистру

parsing:
  allow_first_token_as_article: true  # извлекать артикул из начала названия
```

### Алиасы брендов: `config/brand_aliases.json`

Определяет нормализацию названий брендов.

### Правила парсинга: `config/parsing_rules.json`

Определяет паттерны для распознавания колонок и извлечения размеров.

## Поддерживаемые форматы

- **CSV** (.csv) - с различными разделителями и кодировками
- **Excel** (.xlsx, .xls) - с помощью openpyxl
- **JSON** (.json) - массивы объектов или объекты с вложенными массивами
- **TXT** (.txt) - как CSV или tab-separated
- **Markdown** (.md) - таблицы в формате markdown

## Выходные файлы

### `out/catalog_target.csv`

Единый каталог в формате CSV со схемой:

```
Наименование,Артикул,Аналог,Бренд,D,d,H,m
```

### `out/catalog_target.json`

Тот же каталог в формате JSON (массив объектов).

### `out/run_report.ndjson`

Отчёт о обработке каждого файла в формате NDJSON (по одной строке JSON на файл).

Поля:
- `timestamp` - время обработки
- `filename` - имя файла
- `sha256` - хеш файла
- `status` - статус ('success', 'error', 'skipped')
- `n_rows` - количество строк в файле
- `n_added` - добавлено записей
- `n_skipped` - пропущено дубликатов
- `n_conflicts` - конфликтов размеров
- `error` - сообщение об ошибке (если есть)
- `conflicts` - детали конфликтов (если есть)

### `out/processed_registry.json`

Реестр SHA256-хешей обработанных файлов для предотвращения повторной обработки.

### `logs/app.log`

Лог работы системы.

## Логика обработки

### Распознавание колонок

Система автоматически распознаёт колонки по паттернам из `config/parsing_rules.json`.

Например:
- "Артикул", "обозначение", "designation", "part" → `Артикул`
- "Бренд", "brand", "производитель" → `Бренд`
- "d", "inner", "внутр" → `d` (внутренний диаметр)

### Извлечение размеров из текста

Если размеры не указаны в отдельных колонках, система пытается извлечь их из наименования по паттерну:

```
20x47x14 → d=20, D=47, H=14
```

### Дедупликация

Ключ дедупликации зависит от наличия бренда:
- Если бренд заполнен: `(Артикул, Бренд, D, d, H)`
- Если бренд пуст: `(Артикул, D, d, H)`

### Конфликты размеров

Если для одного и того же артикула и бренда встречаются разные размеры:
- Обе записи добавляются в каталог
- Конфликт фиксируется в отчёте

### Нормализация файлов

После успешной обработки файл переименовывается и перемещается в `processed/`:

```
YYYYMMDD_HHMMSS__<source>__<n_records>__<sha256_8>.<ext>
```

При ошибке файл перемещается в `error/` с добавлением `__ERROR__<code>` в имя.

## Тесты

Запуск тестов:

```bash
pytest -q
```

Запуск конкретного теста:

```bash
pytest tests/test_pipeline_csv.py -v
```

## Примеры использования

### Обработка одного файла

1. Поместите файл в `inbox/`
2. Запустите `python -m app once`
3. Проверьте результат в `out/catalog_target.csv`

### Непрерывная обработка

1. Запустите `python -m app watch`
2. Добавляйте файлы в `inbox/`
3. Система автоматически их обработает

### Проверка отчёта

```bash
cat out/run_report.ndjson | jq '.'
```

## Устранение неполадок

### Файл не обрабатывается

- Проверьте формат файла (поддерживаемые расширения)
- Проверьте размер файла (не превышает ли лимит)
- Проверьте логи в `logs/app.log`

### Неправильное распознавание колонок

- Проверьте паттерны в `config/parsing_rules.json`
- Добавьте новые паттерны для ваших колонок

### Дубликаты в каталоге

- Проверьте, что файлы действительно разные (разные SHA256)
- Проверьте логику дедупликации (возможно, конфликт размеров)

## Архитектура

Система состоит из следующих модулей:

- `app.config` - загрузка конфигурации
- `app.utils` - утилитарные функции
- `app.normalization` - нормализация данных
- `app.parsing` - парсинг различных форматов
- `app.catalog` - управление каталогом
- `app.registry` - реестр обработанных файлов
- `app.report` - генерация отчётов
- `app.processor` - основная логика обработки
- `app.watcher` - наблюдение за директорией

## Лицензия

См. файл LICENSE в корне репозитория.
